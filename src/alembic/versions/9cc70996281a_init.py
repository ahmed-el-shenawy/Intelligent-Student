"""init

Revision ID: 9cc70996281a
Revises: 
Create Date: 2025-10-31 16:53:33.051224

"""
from datetime import datetime
from typing import Sequence, Union
import uuid

from alembic import op
import pgvector
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from helpers.security import hash_password

# revision identifiers, used by Alembic.
revision: str = '9cc70996281a'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('projects',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=100), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_projects')),
    sa.UniqueConstraint('name', name=op.f('uq_projects_name'))
    )
    op.create_table('users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('username', sa.String(length=50), nullable=False),
    sa.Column('hashed_password', sa.String(), nullable=False),
    sa.Column('role', sa.Integer(), server_default='1', nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_users')),
    sa.UniqueConstraint('username', name=op.f('uq_users_username'))
    )
    op.create_table('documents',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('filename', sa.String(length=255), nullable=False),
    sa.Column('metadata_json', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('is_processed', sa.Boolean(), server_default='FALSE', nullable=False),
    sa.Column('is_flushed', sa.Boolean(), server_default='FALSE', nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], name=op.f('fk_documents_project_id_projects'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_documents')),
    sa.UniqueConstraint('project_id', 'filename', name='uq_project_filename')
    )
    op.create_index('idx_documents_is_processed', 'documents', ['is_processed'], unique=False)
    op.create_index('idx_documents_project_filename', 'documents', ['project_id', 'filename'], unique=False)
    op.create_table('project_users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], name=op.f('fk_project_users_project_id_projects'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_project_users_user_id_users'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_project_users')),
    sa.UniqueConstraint('project_id', 'user_id', name='uq_project_user')
    )
    op.create_table('refresh_tokens',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('hashed_token', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_refresh_tokens_user_id_users'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_refresh_tokens')),
    sa.UniqueConstraint('hashed_token', name=op.f('uq_refresh_tokens_hashed_token'))
    )
    op.create_table('user_history',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('history', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], name=op.f('fk_user_history_project_id_projects'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_user_history_user_id_users'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_user_history')),
    sa.UniqueConstraint('user_id', 'project_id', name='uq_user_project_history')
    )
    op.create_index('ix_user_history_user_project', 'user_history', ['user_id', 'project_id'], unique=False)
    op.create_table('chunks',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('text', sa.Text(), nullable=False),
    sa.Column('metadata_json', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], name=op.f('fk_chunks_document_id_documents'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_chunks'))
    )
    op.create_table('vector_embeddings',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('chunk_id', sa.UUID(), nullable=False),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=False),
    sa.ForeignKeyConstraint(['chunk_id'], ['chunks.id'], name=op.f('fk_vector_embeddings_chunk_id_chunks'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], name=op.f('fk_vector_embeddings_document_id_documents'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], name=op.f('fk_vector_embeddings_project_id_projects'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_vector_embeddings')),
    sa.UniqueConstraint('project_id', 'document_id', 'chunk_id', name='uq_project_document_chunk')
    )
    op.create_index('idx_vectors_embedding', 'vector_embeddings', ['embedding'], unique=False, postgresql_using='ivfflat', postgresql_with={'lists': '100'}, postgresql_ops={'embedding': 'vector_cosine_ops'})
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_vectors_embedding', table_name='vector_embeddings', postgresql_using='ivfflat', postgresql_with={'lists': '100'}, postgresql_ops={'embedding': 'vector_cosine_ops'})
    op.drop_table('vector_embeddings')
    op.drop_table('chunks')
    op.drop_index('ix_user_history_user_project', table_name='user_history')
    op.drop_table('user_history')
    op.drop_table('refresh_tokens')
    op.drop_table('project_users')
    op.drop_index('idx_documents_project_filename', table_name='documents')
    op.drop_index('idx_documents_is_processed', table_name='documents')
    op.drop_table('documents')
    op.drop_table('users')
    op.drop_table('projects')
    # ### end Alembic commands ###
